{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProcesoCreacionRedParcelasML.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3yXPV1s7dhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras import optimizers\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
        "from tensorflow.python.keras.layers import  Convolution2D, MaxPooling2D\n",
        "from tensorflow.python.keras import backend as K\n",
        "import shutil\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9Qs9zcbk7Rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def leerParametrosFichero(ruta):\n",
        "  diccionarioParametros = {}\n",
        "  \n",
        "  # Abre archivo en modo lectura\n",
        "  with open(ruta,'r') as archivo:\n",
        "    # inicia bucle infinito para leer línea a línea.\n",
        "    while True: \n",
        "      linea = archivo.readline()  # lee línea.\n",
        "      if not linea: \n",
        "          break  # Si no hay más se rompe bucle.\n",
        "      linea = linea.rstrip() #Quita caracteres vacios y \\n a la derecha.\n",
        "      \n",
        "      key, value = linea.strip().split('=') #dividimos la linea mediante el signo = . izquierda la clave y derecha valor\n",
        "      key = key.strip() #quitamos espacios en blancos de la parte izquierda\n",
        "      key = key.strip(\"'\") #quitamos comillas simples de la parte izquierda\n",
        "      \n",
        "      value = value.strip() # #quitamos espacios en blancos de la parte derecha\n",
        "      value = value.strip(\"'\") # quitamos comillas simples de la parte derecha\n",
        "      \n",
        "      diccionarioParametros[key] = value\n",
        "  archivo.close  # Cierra archivo\n",
        "  \n",
        "  return diccionarioParametros"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08I0R6SnKh7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preparacionGeneradorImagenesEntrenamiento(alt,long,bsize,data_entrenamiento):\n",
        "  entrenamiento_datagen = ImageDataGenerator(rescale=1. / 255, shear_range=0.2,zoom_range=0.2, horizontal_flip=True)\n",
        "  \n",
        "  entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
        "    data_entrenamiento,\n",
        "    target_size=(alt, long),\n",
        "    batch_size=bsize,\n",
        "    class_mode='categorical')\n",
        "  \n",
        "  return entrenamiento_generador\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f5xz7syLSX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preparacionGeneradorImagenesValidacion(alt,long,bsize,data_entrenamiento):\n",
        "  test_datagen = ImageDataGenerator(rescale=1. / 255,validation_split=0.2)\n",
        "  \n",
        "  validacion_generador = test_datagen.flow_from_directory(\n",
        "    data_entrenamiento,\n",
        "    target_size=(alt, long),\n",
        "    batch_size=bsize,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')\n",
        "  \n",
        "  return validacion_generador"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1tigX6OApO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def procesoClasificacionParcelasML(parametros):\n",
        "  \n",
        "  print(parametros)\n",
        "  \n",
        "  enFormatoZIP = eval(parametros['enFormatoZIP'])\n",
        "  \n",
        "  try:\n",
        "     rutaDatosEntrenamiento = parametros['rutaDatosEntrenamiento']    \n",
        "     os.stat(rutaDatosEntrenamiento)\n",
        "   \n",
        "     print(\"Ya existe el directorio, no es necesario descomprimir el archivos ZIP.\")\n",
        "  except:\n",
        "    if (enFormatoZIP):\n",
        "      \n",
        "      #Ruta donde se encuentra los ficheros ZIP con los datos de entrenamiento y validación.\n",
        "      rutaDatosEntrenamientoZIP = parametros['rutaDatosEntrenamientoZIP']\n",
        "    \n",
        "      #Ruta donde queremos que de descompriman los datos de entrenamiento y validación.\n",
        "      rutaDatosEntrenamiento = parametros['rutaDatosEntrenamiento']\n",
        "      \n",
        "      if \".zip\" not in rutaDatosEntrenamientoZIP and \".zip\" not in rutaDatosValidacionZIP:  \n",
        "        \n",
        "        rutaDatosEntrenamientoZIP = rutaDatosEntrenamientoZIP+'.zip'\n",
        "        \n",
        "        print(\"------- Descompriminedo los Datos de Entrenamiento... -------\")\n",
        "        shutil.unpack_archive(rutaDatosEntrenamientoZIP) \n",
        "       \n",
        "      else:\n",
        "        print(\"------- Descompriminedo los Datos de Entrenamiento... -------\")\n",
        "        shutil.unpack_archive(rutaDatosEntrenamientoZIP)\n",
        "    \n",
        "    else:\n",
        "      rutaDatosEntrenamiento = parametros['rutaDatosEntrenamiento']\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  print(\"------- Leyendo las carácteristicas de la Red... -------\")\n",
        "\n",
        "  #Parametros para la red.\n",
        "  epochs = int(parametros['epochs'])\n",
        "  print(\"El número de Epochs es: \",epochs)\n",
        "  \n",
        "  longitudImagen = int(parametros['longitudImagen'])\n",
        "  print(\"La Longitud para las imágenes es: \",longitudImagen)\n",
        "  \n",
        "  alturaImagen = int(parametros['alturaImagen'])\n",
        "  print(\"La Altura para las imágenes es: \",alturaImagen)\n",
        "\n",
        "  batch_size = int(parametros['batch_size'])\n",
        "  print(\"El número de Batch Sizee es: \",batch_size)\n",
        "  \n",
        "  pasos = int(parametros['pasos'])\n",
        "  print(\"El número de Pasos es: \", pasos)\n",
        "  \n",
        "  validation_steps = int(parametros['validation_steps'])\n",
        "  print(\"El número de Pasos de Validacion es: \",validation_steps)\n",
        "\n",
        "  filtrosConv1 = int(parametros['filtrosConv1'])\n",
        "  print(\"El numero del primer filtro de Convolución es: \",filtrosConv1)\n",
        "  \n",
        "  filtrosConv2 = int(parametros['filtrosConv2'])\n",
        "  print(\"El numero del segundo filtro de Convolución es: \",filtrosConv2)\n",
        "\n",
        "  tamano_filtro1 = eval(parametros['tamano_filtro1'])\n",
        "  print(\"El numero del primer filtro de Convolución es: \",tamano_filtro1)\n",
        "\n",
        "  tamano_filtro2 = eval(parametros['tamano_filtro2'])\n",
        "  print(\"El tamaño del segundo filtro de Convolución es: \", tamano_filtro2)\n",
        "\n",
        "  tamano_pool = eval(parametros['tamano_pool'])\n",
        "  print(\"El tamaño del filtro de Pooling es: \",tamano_pool)\n",
        "\n",
        "  clases = int(parametros['clases'])\n",
        "  print(\"El número de clases es: \", clases)\n",
        "  \n",
        "  lr = float(parametros['lr'])\n",
        "  print(\"El número de Learning Rate: \", lr)\n",
        "  \n",
        "  \n",
        "  print(\"------- Creando los generadores... -------\")\n",
        "  generadorEntrenamiento = preparacionGeneradorImagenesEntrenamiento(alturaImagen,longitudImagen,batch_size,rutaDatosEntrenamiento)\n",
        "  generadorValidacion = preparacionGeneradorImagenesValidacion(alturaImagen,longitudImagen,batch_size,rutaDatosEntrenamiento)\n",
        "  \n",
        "  print(\"------- Construyendo la red... -------\")\n",
        "  parcelasModel = Sequential()\n",
        "  parcelasModel.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", input_shape=(longitudImagen, alturaImagen, 3), activation='relu'))\n",
        "  parcelasModel.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "  parcelasModel.add(Convolution2D(filtrosConv2, tamano_filtro2, padding =\"same\"))\n",
        "  parcelasModel.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "  parcelasModel.add(Flatten())\n",
        "  parcelasModel.add(Dense(256, activation='relu'))\n",
        "  parcelasModel.add(Dropout(0.5))\n",
        "  parcelasModel.add(Dense(clases, activation='softmax'))\n",
        "\n",
        "  print(\"------- Red construida -------\")\n",
        "  parcelasModel.summary()\n",
        "  \n",
        "  print(\"------- Compilando la red... -------\")\n",
        "  parcelasModel.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=lr), metrics=['accuracy'])\n",
        "  \n",
        "  print(\"------- Entrenando la red... -------\")\n",
        "  parcelasModel.fit_generator(generadorEntrenamiento, steps_per_epoch=pasos, epochs=epochs, validation_data=generadorValidacion, validation_steps=validation_steps)\n",
        "\n",
        "\n",
        "  rutaDatosModelo = parametros['rutaDatosModelo']\n",
        "  if not os.path.exists(rutaDatosModelo):\n",
        "    os.mkdir(rutaDatosModelo)\n",
        "  \n",
        "\n",
        "  print(\"------- Guardando el modelo y los pesos de la red... -------\")\n",
        "   \n",
        "  nombreModelo = parametros['nombreModelo']\n",
        "  nombrePesos = parametros['nombrePesos']\n",
        "  parcelasModel.save(rutaDatosModelo +'/'+ nombreModelo+'.h5')\n",
        "  parcelasModel.save_weights(rutaDatosModelo +'/'+ nombrePesos+'.h5')\n",
        "  \n",
        "  \n",
        "  \n",
        "  # --- COMPRIMIMOS LA CARPETA RESULTANTE ------\n",
        "  \n",
        "  print(\"------- Comprimiendo los ficheros... -------\")\n",
        "  nombreModeloZIP = parametros['nombreModeloZIP']\n",
        "  \n",
        "  shutil.make_archive(nombreModeloZIP, 'zip', rutaDatosModelo) #NombreDelZIP,formato,y directorio a comprimir\n",
        "  \n",
        "  \n",
        "  print(\"------- Fin del preoceso de creación de la red --------\")  \n",
        "  \n",
        "  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG7tUFKhPnmY",
        "colab_type": "code",
        "outputId": "d776a90f-f470-4d3a-c7bd-01448c4151dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "param = leerParametrosFichero('/content/ficheroCreacionCNN.txt')\n",
        "procesoClasificacionParcelasML(param)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'enFormatoZIP': 'True', 'rutaDatosEntrenamientoZIP': '/content/DatosEntrenamiento.zip', 'rutaDatosEntrenamiento': '/content/DatosEntrenamiento', 'epochs': '20', 'longitudImagen': '28', 'alturaImagen': '28', 'batch_size': '32', 'pasos': '1000', 'validation_steps': '300', 'filtrosConv1': '32', 'filtrosConv2': '64', 'tamano_filtro1': '(3, 3)', 'tamano_filtro2': '(2, 2)', 'tamano_pool': '(2, 2)', 'clases': '3', 'lr': '0.0004', 'rutaDatosModelo': '/content/ModeloTabaco', 'nombreModelo': 'modeloTabaco', 'nombrePesos': 'pesosTabaco', 'nombreModeloZIP': 'ModeloyPesosTabaco'}\n",
            "------- Descompriminedo los Datos de Entrenamiento... -------\n",
            "------- Leyendo las carácteristicas de la Red... -------\n",
            "El número de Epochs es:  20\n",
            "La Longitud para las imágenes es:  28\n",
            "La Altura para las imágenes es:  28\n",
            "El número de Batch Sizee es:  32\n",
            "El número de Pasos es:  1000\n",
            "El número de Pasos de Validacion es:  300\n",
            "El numero del primer filtro de Convolución es:  32\n",
            "El numero del segundo filtro de Convolución es:  64\n",
            "El numero del primer filtro de Convolución es:  (3, 3)\n",
            "El tamaño del segundo filtro de Convolución es:  (2, 2)\n",
            "El tamaño del filtro de Pooling es:  (2, 2)\n",
            "El número de clases es:  3\n",
            "El número de Learning Rate:  0.0004\n",
            "------- Creando los generadores... -------\n",
            "Found 7230 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0630 18:15:44.165823 139969979262848 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 1446 images belonging to 3 classes.\n",
            "------- Construyendo la red... -------\n",
            "------- Red construida -------\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               803072    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 812,995\n",
            "Trainable params: 812,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "------- Compilando la red... -------\n",
            "------- Entrenando la red... -------\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.2881 - acc: 0.8831 - val_loss: 0.0578 - val_acc: 0.9922\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0489 - acc: 0.9864 - val_loss: 0.0028 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0218 - acc: 0.9937 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0143 - acc: 0.9962 - val_loss: 3.8332e-04 - val_acc: 1.0000\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0164 - acc: 0.9947 - val_loss: 3.8881e-04 - val_acc: 1.0000\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0113 - acc: 0.9963 - val_loss: 1.9382e-04 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0114 - acc: 0.9962 - val_loss: 5.7650e-05 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0114 - acc: 0.9961 - val_loss: 8.3992e-05 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0087 - acc: 0.9972 - val_loss: 4.6253e-06 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0091 - acc: 0.9966 - val_loss: 1.2125e-05 - val_acc: 1.0000\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0082 - acc: 0.9970 - val_loss: 1.1058e-05 - val_acc: 1.0000\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0115 - acc: 0.9962 - val_loss: 2.6152e-06 - val_acc: 1.0000\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0073 - acc: 0.9974 - val_loss: 7.1206e-06 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0073 - acc: 0.9975 - val_loss: 6.7341e-06 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0073 - acc: 0.9975 - val_loss: 2.8503e-04 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0077 - acc: 0.9974 - val_loss: 1.1927e-05 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0063 - acc: 0.9980 - val_loss: 5.1236e-07 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0081 - acc: 0.9972 - val_loss: 1.8501e-06 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 3.9057e-07 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0062 - acc: 0.9980 - val_loss: 6.3781e-07 - val_acc: 1.0000\n",
            "------- Guardando el modelo y los pesos de la red... -------\n",
            "------- Comprimiendo los ficheros... -------\n",
            "------- Fin del preoceso de creación de la red --------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}